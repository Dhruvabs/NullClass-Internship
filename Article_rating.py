from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.llms import Ollama
import streamlit as st
import os

prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are judge of article that are generated by other LLMs. Judge article based on given metrics- Fluency, Relevance, Creativity, Factual accuracy."
        ),
        (
            "user",
            "Article:{article}"
        )
    ]
)
st.title ("Article Performance accessing using LLM")
article = st.text_input("Enter the article...........")

llm = Ollama(model = "mistral-small3.1" )

output_parser = StrOutputParser()
chain = prompt | llm | output_parser

if article:
    st.write(chain.invoke({"article":article}))